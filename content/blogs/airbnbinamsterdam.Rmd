---
categories:
- ""
- ""
date: "2017-10-31T22:26:09-05:00"
description:
draft: false
image: julienphoto.jpg
keywords: ""
slug: airbnbinamsterdam
title: Find your stay in Amsterdam
---

### **What did we research?**

Hi, I'm Julien. My team tried to come up with some insight on amsterdam airbnb!
have fun!


```{r setup, include=FALSE}
# leave this chunk alone
options(knitr.table.format = "html") 
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
  comment = NA, dpi = 300)
```


```{r load-libraries, echo=FALSE}

library(tidyverse) # the usual stuff: dplyr, readr, and other goodies
library(lubridate) # to handle dates
library(GGally) # for correlation-scatter plot matrix
library(ggfortify) # to produce residual diagnostic plots
library(rsample) # to split dataframe in training- & testing sets
library(janitor) # clean_names()
library(broom) # use broom:augment() to get tidy table with regression output, residuals, etc
library(huxtable) # to get summary table of all models produced
library(kableExtra) # for formatting tables
library(moderndive) # for getting regression tables
library(skimr) # for skim
library(mosaic)
library(leaflet) # for interactive HTML maps
library(tidytext)
library(viridis)
library(vroom)
library(rsample)
library(car)
```


# Executive Summary

> The aim of the analysis is to build a prediction model that can estimate the average cost for 2 people to stay in an AirBnB in Amsterdam for 4 nights. As such, we analysed data about Airbnb listings in the city and identified predictors that are highly relevant to the price and fitted several models. Those predictors are selected first based on common sense and were analysed in terms of their price expanatory power. We then tested several models in order to find out which could predict the price better. The best model was chosen based on how well it helps to predict the prices given different inputs. The price is then estimated based on the best model. The best model includes variables such as property type, number_of_reviews, review_scores_rating, bathrooms, bedrooms, accommodates, host_is_superhost, neighbourhood_simplified, availability_30 and reviews_per_month. These are consistent with common sense metrics that would lead to increases or decreases in price.

Even though there are many variables in the dataframe, here is a quick description of some of the variables collected

- `price` = cost per night 
- `property_type`: type of accommodation (House, Apartment, etc.)
- `room_type`:

  - Entire home/apt (guests have entire place to themselves)
  - Private room (Guests have private room to sleep, all other rooms shared)
  - Shared room (Guests sleep in room shared with others)

- `number_of_reviews`: Total number of reviews for the listing
- `review_scores_rating`: Average review score (0 - 100)
- `longitude` , `latitude`: geographical coordinates to help us locate the listing
- `neighbourhood*`: three variables on a few major neighbourhoods in each city 

```{r load_data, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}

# use cache=TRUE so you dont donwload the data everytime you knit

listings <- vroom("http://data.insideairbnb.com/the-netherlands/north-holland/amsterdam/2021-09-07/data/listings.csv.gz") %>% 
       clean_names()

```

# Exploratory Data Analysis (EDA)

In the [R4DS Exploratory Data Analysis chapter](http://r4ds.had.co.nz/exploratory-data-analysis.html){target="_blank"}, the authors state:

> "Your goal during EDA is to develop an understanding of your data. The easiest way to do this is to use questions as tools to guide your investigation... EDA is fundamentally a creative process. And like most creative processes, the key to asking quality questions is to generate a large quantity of questions."


Conduct a thorough EDA. Recall that an EDA involves three things:

* Looking at the raw values.
    * `dplyr::glimpse()`
* Computing summary statistics of the variables of interest, or finding NAs
    * `mosaic::favstats()`
    * `skimr::skim()`
* Creating informative visualizations.
    * `ggplot2::ggplot()`
        * `geom_histogram()` or `geom_density()` for numeric continuous variables
        * `geom_bar()` or `geom_col()` for categorical variables
    * `GGally::ggpairs()` for scaterrlot/correlation matrix
        * Note that you can add transparency to points/density plots in the `aes` call, for example: `aes(colour = gender, alpha = 0.4)`
        
You may wish to have a level 1 header (`#`) for your EDA, then use level 2 sub-headers (`##`) to make sure you cover all three EDA bases. **At a minimum** you should address these questions:

- How many variables/columns? How many rows/observations?
- Which variables are numbers?
- Which are categorical or *factor* variables (numeric or character variables with variables that have a fixed and known set of possible values?
- What are the correlations between variables? Does each scatterplot support a linear relationship between variables? Do any of the correlations appear to be conditional on the value of a categorical variable?

At this stage, you may also find you want to use `filter`, `mutate`, `arrange`, `select`, or `count`. Let your questions lead you! 

> In all cases, please think about the message your plot is conveying. Don’t just say "This is my X-axis, this is my Y-axis", but rather what’s the **so what** of the plot. Tell some sort of story and speculate about the differences in the patterns in no more than a paragraph.

## Data wrangling

Once you load the data, it's always a good idea to use `glimpse` to see what kind of variables you have and what data type (`chr`, `num`, `logical`, `date`, etc) they are. 

Notice that some of the price data (`price`) is given as a character string, e.g., "$176.00"

Since `price` is a quantitative variable, we need to make sure it is stored as numeric data `num` in the dataframe. To do so, we will first use `readr::parse_number()` which drops any non-numeric characters before or after the first number

  
Use `typeof(listing$price)` to confirm that `price` is now stored as a number.

```{r}

glimpse(listings)
favstats(listings$id)
skim(listings)

#Storing the price as a number
listings_clean <- listings %>% 
  filter(name != "",
         host_location != "") %>% 
  mutate(price = parse_number(price),
         bathrooms = parse_number(gsub( "\\s.*", "", bathrooms_text))) %>% 
  filter(bathrooms != "")

typeof(listings_clean$price)

skim(listings_clean)

#explore the distribution of bedrooms and beds
ggplot(listings_clean) +
  geom_density(aes(x=bedrooms))+
  theme_bw()

ggplot(listings_clean) +
  geom_density(aes(x=beds))+
  theme_bw()

ggplot(listings_clean) +
  geom_density(aes(x=price))+
  theme_bw()

```
> We noticed that for each variable there are a lot of outliers outside where the majority data concentrate and we would like to remove those uncommon observations later.

```{r}
# assumptions of the followings variables are made in accordance to common choices for tourists
listings_clean1 <- listings_clean %>% filter(bedrooms < 5) 
listings_clean3 <- listings_clean1 %>% filter (minimum_nights <= 4)
listings_clean4 <- listings_clean3 %>% filter (price < 1500) # Everything above that would be extraordinarily expensive
listings_clean5 <- listings_clean4 %>% filter (accommodates > 1)

# cleaning the data and choosing the relevant variables
listings_smaller <- listings_clean5 %>% 
  select(host_location,
         neighbourhood,
         neighbourhood_cleansed,
         neighbourhood_group_cleansed,
         property_type,
         room_type,
         accommodates,
         bathrooms,
         bathrooms_text,
         bedrooms,
         beds,
         price,
         review_scores_rating,
         minimum_nights,
         maximum_nights,
         property_type,
         latitude,
         longitude,
         host_is_superhost,
         instant_bookable,
         availability_30,
         reviews_per_month)
```
## Key Explanatory Variables
```{r}
# investigate the correlation among some key variables
listings_smaller %>% 
  select(price, bedrooms, beds, bathrooms, review_scores_rating) %>% 
  ggpairs(aes(alpha = 0.4))

#box plot for number of beds (1 and 2) relative to prices
ggplot(listings_smaller, aes(x = price)) +
  geom_boxplot() +
  facet_wrap(~bedrooms)

#comparison of review scores and prices
ggplot(listings_smaller, aes(x = review_scores_rating, y = price)) +
  geom_point(aes(alpha = 0.4))
  


```

> Plot 1 showcases that 2 bedrooms are relatively more (but only slightly) expensive than 1 bedroom in Amsterdam; however the range and variability of prices of 2 bedrooom rooms appears to be greater than a 1 bedroom, with the 75% percentile being significantly higher for 2 bedrooms compared to 1. The moderately strong positive correlation of 0.378 between bedrooms and price also indicates the same. Similarly, the plots also indicate that Higher ratings is also associated with higher prices, even though the correlation between the two variables is only weakly positive.

> 0 review ratings do not tell us much about the quality of the accomodation nor the price. It can be explained by that new listing usually don't have reviews and 0 ratings are therefore not informative

Next, we look at the variable `property_type`. We can use the `count` function to determine how many categories there are their frequency. What are the top 4 most common property types? What proportion of the total listings do they make up? 

Since the vast majority of the observations in the data are one of the top four or five property types, we would like to create a simplified version of `property_type` variable that has 5 categories: the top four categories and `Other`. Fill in the code below to create `prop_type_simplified`.

```{r}
# property type
listings_clean5 %>% 
  group_by(property_type) %>%
  summarise(count = n()) %>% 
  arrange(desc(count))

#creating a simplified version of `property_type`
listings_clean5 <- listings_clean5 %>%
  mutate(prop_type_simplified = case_when(
    property_type %in% c("Entire rental unit","Entire residential home", "Entire townhouse","Private room in rental unit") ~ property_type, 
    TRUE ~ "Other"
  ))
  
```
> As shown in the table above, the four most common property types in Airbnb Amsterdam are "Entire rental unit", "private room in rental unit", "entire condo" and "entire residential home". Collectively they account for the majority of the property types available in Amsterdam. The significantly high number of row houses, condos and houses with lofts relative to other major cities like Rotterdam (more metropolitan with numerous skyscapers) also justifies the relatively high number of condos and lofts.

Use the code below to check that `prop_type_simplified` was correctly made.

```{r}
listings_clean5 %>%
  count(property_type, prop_type_simplified) %>%
  arrange(desc(n))        
```        

Airbnb is most commonly used for travel purposes, i.e., as an alternative to traditional hotels. We only want to include  listings in our regression analysis that are intended for travel purposes:

- What are the  most common values for the variable `minimum_nights`? 
- Is there any value among the common values that stands out? 
- What is the likely intended purpose for Airbnb listings with this seemingly unusual value for `minimum_nights`?

```{r}
listings %>%
  count(minimum_nights) %>%
  arrange(desc(n))  
# Filtered out everything above 4 min. nights in listings_clean
ggplot(listings_clean5, aes(x=minimum_nights)) + 
  geom_histogram()

```

> The most common values appearing for the variable "minimum nights" are 1,2 and 3 nights. Out of these 3 values, 2 nights is by far the most commonly occuring value. Given the fact that Amsterdam is amongst one of the top cities for a weekend visit by tourists residing in UK and western Europe, a minimum of 2 nights is seems logical. Similarly, 30 nights is the 9th highest with it being only 1 of 2 values to be greater than 10. The fact that any reservation >29 days is considered as a "long-term stay" and the host can earn significant benefits from the same could explain why a minimum of 30 nights is so common.  



Filter the airbnb data so that it only includes observations with `minimum_nights <= 4`

        
# Mapping 

Visualisations of feature distributions and their relations are key to understanding a data set, and they can open up new lines of exploration. While we do not have time to go into all the wonderful geospatial visualisations one can do with R, you can use the following code to start with a map of your city, and overlay all AirBnB coordinates to get an overview of the spatial distribution of AirBnB rentals. For this visualisation we use the `leaflet` package, which includes a variety of tools for interactive maps, so you can easily zoom in-out, click on a point to get the actual AirBnB listing for that specific point, etc.

The following code, having downloaded a dataframe `listings` with all AirbnB listings in Milan, will plot on the map all AirBnBs where `minimum_nights` is less than equal to four (4). You could learn more about `leaflet`, by following [the relevant Datacamp course on mapping with leaflet](https://www.datacamp.com/courses/interactive-maps-with-leaflet-in-r)


```{r, out.width = '80%'}

leaflet(data = filter(listings_clean5)) %>% 
  addProviderTiles("OpenStreetMap.Mapnik") %>% 
  addCircleMarkers(lng = ~longitude, 
                   lat = ~latitude, 
                   radius = 1, 
                   fillColor = "blue", 
                   fillOpacity = 0.4, 
                   popup = ~listing_url,
                   label = ~property_type)
```

> The concentration of the listings are around central amsterdam and south-east Amsterdam. This is an expected result given that central and south-east amsterdam tend to the key tourist spots like the "nine streets" and thus justifies the greater concentration of listings in this areas.  

# Regression Analysis

For the target variable $Y$, we will use the cost for two people to stay at an Airbnb location for four (4) nights. 

Create a new variable called `price_4_nights` that uses `price`, and `accomodates` to calculate the total cost for two people to stay at the Airbnb property for 4 nights. This is the variable $Y$ we want to explain.

Use histograms or density plots to examine the distributions of `price_4_nights` and `log(price_4_nights)`. Which variable should you use for the regression model? Why?

Fit a regression model called `model1` with the following explanatory variables: `prop_type_simplified`, `number_of_reviews`, and `review_scores_rating`. 

- Interpret the coefficient `review_scores_rating` in terms of `price_4_nights`.
- Interpret the coefficient of `prop_type_simplified` in terms of `price_4_nights`.

We want to determine if `room_type` is a significant predictor of the cost for 4 nights, given everything else in the model. Fit a regression model called model2 that includes all of the explananatory variables in `model1` plus `room_type`. 

```{r}

listings_clean5 <- listings_clean5 %>% 
  mutate(price_4_nights = price * 4) %>%  # we did not include accomodates because the given price is already including all people
  filter(review_scores_rating > 0) # we exclude 0's because new listing usually don't have reviews and are therefore not informative
  

ggplot(listings_clean5, aes(x = price_4_nights)) +
  geom_density()

ggplot(listings_clean5, aes(x = log(price_4_nights))) +
  geom_density()

```

## Model 1
```{r}

model1 <- lm(log(price_4_nights) ~ prop_type_simplified +
               number_of_reviews +
               review_scores_rating,
             data = listings_clean5)

summary(model1)


```

## Model 2

```{r}

model2 <- lm(log(price_4_nights) ~ prop_type_simplified +
               number_of_reviews +
               review_scores_rating +
               room_type,
             data = listings_clean5)

summary(model2)

vif(model2)

```

> The variable (log(price_4_nights)) has been used as it effectively captures the compunding effect; it also allows for an earier and more meaningful interpretation of the regression results (in percentage terms). This is also showcased by the density plots; the variable price_4_nights is right skewed whereas the logged variable reflects a normal distribution bell curve.

## Further variables/questions to explore on our own

Our dataset has many more variables, so here are some ideas on how you can extend your analysis

1. Are the number of `bathrooms`, `bedrooms`, `beds`, or size of the house (`accomodates`) significant predictors of `price_4_nights`? Or might these be co-linear variables?
1. Do superhosts `(host_is_superhost`) command a pricing premium, after controlling for other variables?
1. Some hosts allow you to immediately book their listing (`instant_bookable == TRUE`), while a non-trivial proportion don't. After controlling for other variables, is `instant_bookable` a significant predictor of `price_4_nights`?
1. For all cities, there are 3 variables that relate to neighbourhoods: `neighbourhood`, `neighbourhood_cleansed`, and `neighbourhood_group_cleansed`. There are typically more than 20 neighbourhoods in each city, and it wouldn't make sense to include them all in your model. Use your city knowledge, or ask someone with city knowledge, and see whether you can group neighbourhoods together so the majority of listings falls in fewer (5-6 max) geographical areas. You would thus need to create a new categorical variabale `neighbourhood_simplified` and determine whether location is a predictor of `price_4_nights`
1. What is the effect of `avalability_30` or `reviews_per_month` on `price_4_nights`, after we control for other variables?


## Model 3

```{r}

model3 <- lm(log(price_4_nights) ~
               prop_type_simplified +
               number_of_reviews +
               review_scores_rating +
               # room_type + GVIF higher than 5
               bathrooms +
               bedrooms +
               beds +
               accommodates +
               host_is_superhost +
               instant_bookable,
             data = listings_clean5)

summary(model3)

vif(model3)


listings_clean5 <- listings_clean5 %>% 
  mutate(neighbourhood_simplified = case_when(neighbourhood_cleansed %in% c("Oostelijk Havengebied - Indische Buurt",
                                                                             "Oud-Oost",
                                                                             "Watergraafsmeer",
                                                                             "Noord-Oost",
                                                                             "IJburg - Zeeburgereiland",
                                                                             "IJburg - Zeeburgereiland",
                                                                             "Gaasperdam - Driemond",
                                                                             "Bijlmer-Oost")~"East",
                                              neighbourhood_cleansed %in% c("Centrum-Oost",
                                                                            "Centrum-West",
                                                                            "De Pijp - Rivierenbuurt",
                                                                            "Bijlmer-Centrum")~"Center",
                                              neighbourhood_cleansed %in% c("De Baarsjes - Oud-West",
                                                                            "Westerpark",
                                                                            "Slotervaart",
                                                                            "Bos en Lommer",
                                                                            "De Aker - Nieuw Sloten",
                                                                            "Osdorp",
                                                                            "Geuzenveld - Slotermeer")~"West",
                                              neighbourhood_cleansed %in% c("Zuid",
                                                                            "Buitenveldert - Zuidas")~"South",
                                              neighbourhood_cleansed %in% c("Noord-West",
                                                                            "Oud-Noord")~"North"))
                                                
                                              
unique(listings_clean$neighbourhood_simplified)
```

## Model 4
```{r}


model4 <- lm(log(price_4_nights) ~ neighbourhood_simplified, data = listings_clean5)

summary(model4)

```
## Model 5
```{r}
model5 <- lm(log(price_4_nights) ~
               prop_type_simplified +
               number_of_reviews +
               review_scores_rating +
               # room_type + GVIF higher than 5
               bathrooms +
               bedrooms +
               beds +
               accommodates +
               host_is_superhost +
               instant_bookable +
               neighbourhood_simplified +
               availability_30 +
               reviews_per_month,
             data = listings_clean5)

summary(model5)

vif(model5)
autoplot(model5)



```

## Model 6
> Removed variable beds due to high correlation with bedrooms and variable instant_bookable which is insignificant in model 5.
```{r}

model6 <- lm(log(price_4_nights) ~
               prop_type_simplified +
               number_of_reviews +
               review_scores_rating +
               # room_type + GVIF higher than 5
               bathrooms +
               bedrooms +
               accommodates +
               host_is_superhost +
               neighbourhood_simplified +
               availability_30 +
               reviews_per_month,
             data = listings_clean5)

summary(model6)

```
## Diagnostics, collinearity, summary tables

As you keep building your models, it makes sense to:

1. Check the residuals, using `autoplot(model_x)`
1. As you start building models with more explanatory variables, make sure you use `car::vif(model_x)`` to calculate the **Variance Inflation Factor (VIF)** for your predictors and determine whether you have colinear variables. A general guideline is that a VIF larger than 5 or 10 is large, and your model may suffer from collinearity. Remove the variable in question and run your model again without it.

```{r}

huxreg(model1, model2, model3, model4, model5, model6)

# Prediction using model6; model 6 has by far the highest R^2 and is less prone to collinearity than model5

listings_selection <- listings_clean5 %>% 
  filter(prop_type_simplified == "Private room in rental unit",
         number_of_reviews >= 10,
         review_scores_rating / 5 >= 0.9)

set.seed(1234)

train_test_split <- initial_split(listings_selection, prop = 0.75)
listings_train <- training(train_test_split)
listings_test <- testing(train_test_split)

rmse_train <- listings_train %>% 
  mutate(predictions = predict(model6, .)) %>% 
  summarise(sqrt(sum(predictions - log(price_4_nights))**2/n())) %>% 
  pull()

rmse_train # 0.05610197

rmse_test <- listings_test %>% 
  mutate(predictions = predict(model6, .)) %>% 
  summarise(sqrt(sum(predictions - log(price_4_nights))**2/n())) %>% 
  pull()

rmse_test # 0.2981508


listings_specifications <- tibble(prop_type_simplified = "Private room in rental unit",
               number_of_reviews = 10,
               review_scores_rating = 0.9 * 5,
               # room_type + GVIF higher than 5
               bathrooms = 2,
               bedrooms = 2,
               accommodates = 4,
               host_is_superhost = TRUE,
               neighbourhood_simplified = "Center",
               availability_30 = 4,
               reviews_per_month = 5)

exp(predict(model6, newdata = listings_specifications, interval = "confidence"))

# 95% CI for price for our specifications between $545.66 and $589.72 for our trip


```

>Regression Analysis
From the Analysis above we can see that model6 is the best model to use out of the 6 models. Model6 explains us the highest variance of 45.8% in Prices while the rest are much below that with Model3 explaining 37.5% of the variance , Model5 45.7%, Model2 22.7%, Model1 17.1% and Model4 only 3.1%. Furthermore, Model6 incorporates the highest number of significant variables in model making it more robust and Explanatory than any of the other models. 
Hence, due to the aforementioned reasons we believe that Model6 is the best Model that should be used for further analysis.

> The number of bathrooms is significant at the 1% level and "accomodates" is significant at the 0.1% level. Similarly, the variable "bedroom" is also significant at the 5% level in model 5. This indicates that the independant variables do improve the regression model and thus allow for a more sound prediction of the expected price. The accomodation variable can be interpreted as - an increase in the individuals residing leads to a 14.9% rise in price. Similarly, an increase in the bedroom and bathroom leads to a 10.2% and 11.9% increase in the relevant price respectively. This is logical given that more 2 bedrooms corressponds to a larger flat/hotel and thus is likely to cost more.
Controlling for "host being a super-host" also suggests that a super-host tends to charge a  5.6% higher price than a normal host, however, this coefficient is statistically insignificant. Analogous to being a super host, the variable "instant book" is also statistically insiginicant at the 5% level and hence does not appear to have a large impact on the dependant variable (price_4_nights)
The 4 variables "neighbourhood simplified south, north, east and west" are streamlined to capture the effect of location on the dependant variable. As showcased in the table above, all 4 variables are statistically significant at the 0.1% level. The coefficients are all negative which suggests that, for example, staying in a listing located in the north leads to a 28.1% decline in expected price for 4 nights. This also appears to be logical as, people using airbnb in Amsterdam for 4 nights are likely to be tourists and thus will target a listing in central Amsterdam. This lack of demand for staying outside the central region indicates the negative effect of location on price.
Lastly, the variable "availability_30" is also statistically significant at the 0.1% level and thus suggests that the availability of the listing does have an impact on the listings price. Surpirisngly, the impact of the variable "listings_per_month" is insignificant and thus does not appear to have a commanding impact on the listings price. This could be due to several factors - tourists may be more concerned with the convenience and the location of the listing rather than the reviews, similarly, tourists could also potentially use Amsterdam as a 'gateway to western Europe' and thus the reviews are unlikely to have a significant impact on the listings price




1. Create a summary table, using `huxtable` (https://mfa2022.netlify.app/example/modelling_side_by_side_tables/) that shows which models you worked on, which predictors are significant, the adjusted $R^2$, and the Residual Standard Error.
1. Finally, you must use the best model you came up with for prediction. Suppose you are planning to visit the city you have been assigned to over reading week, and you want to stay in an Airbnb. Find Airbnb's in your destination city that are apartments with a private room, have at least 10 reviews, and an average rating of at least 90. Use your best model to predict the total cost to stay at this Airbnb for 4 nights. Include the appropriate 95% interval with your prediction. Report the point prediction and interval in terms of `price_4_nights`. 
  - if you used a log(price_4_nights) model, make sure you anti-log to convert the value in $. You can read more about [hot to interpret a regression model when some variables are log transformed here](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/)


# Deliverables


- By midnight on Monday 17 Oct 2022, you must upload on Canvas a short presentation (max 4-5 slides) with your findings, as some groups will be asked to present in class. You should present your Exploratory Data Analysis, as well as your best model. In addition, you must upload on Canvas your final report, written  using R Markdown to introduce, frame, and describe your story and findings. You should include the following in the memo:

1. Executive Summary: Based on your best model, indicate the factors that influence `price_4_nights`.
This should be written for an intelligent but non-technical audience. All
other sections can include technical writing.
2. Data Exploration and Feature Selection: Present key elements of the data, including tables and
graphs that help the reader understand the important variables in the dataset. Describe how the
data was cleaned and prepared, including feature selection, transformations, interactions, and
other approaches you considered.
3. Model Selection and Validation: Describe the model fitting and validation process used. State
the model you selected and why they are preferable to other choices.
4. Findings and Recommendations: Interpret the results of the selected model and discuss
additional steps that might improve the analysis
  
  

Remember to follow R Markdown etiquette rules and style; don't have the Rmd output extraneous messages or warnings, include summary tables in nice tables (use `kableExtra`), and remove any placeholder texts from past Rmd templates; in other words, (i.e. I don't want to see stuff I wrote in your final report.)
  
  
# Acknowledgements

- The data for this project is from [insideairbnb.com](insideairbnb.com)